# STAIR: Improving Safety Alignment with Introspective Reasoning

[![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2406.07057)
![GitHub stars](https://img.shields.io/github/stars/thu-ml/STAIR?style=social)

**üöß Codebase, datasets & models are coming soon!**  
**‚≠ê Star to stay updated on our release progress!**

<img src="resources/intro.png" width="80%"><!-- Replace with actual image path -->

Official implementation of **STAIR**, the framework presented in our paper "*Improving Safety Alignment with Introspective Reasoning*". STAIR enhances LLM safety with the incorporation step-by-step analysis of potential risks, providing more robust alignment while better maintaining model capabilities.


### TODO List
- [ ] <img src="resources/github-brands-solid.svg" width="20" height="20"> Official implementation of STAIR, including Safety-Informed MCTS (SI-MCTS), test-time scaling, etc.
- [ ] ü§ó SFT dataset of structured CoT format alignment
- [ ] ü§ó Model weights of LLMs (Llama-3.1-8B-Instruct, Qwen2-7B-Instruct) aligned with STAIR


